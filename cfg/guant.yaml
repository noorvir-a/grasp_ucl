# Directories
dataset_dir: /home/noorvir/datasets/gqcnn/dexnet_large_ucl/
cache_dir: /home/noorvir/datasets/gqcnn/cache/
summary_dir: /home/noorvir/tf_models/GUAN-t/summaries/
checkpoint_dir: /home/noorvir/tf_models/GUAN-t/checkpoints/
model_dir: /home/noorvir/tf_models/GUAN-t/pre_trained/         # path to trained GUAN-t model

dataset_name: dexnet_large_ucl

dataset_config: /home/noorvir/catkin_ws/src/grasp_ucl/cfg/datasets.yaml
pt_weights_filename: /home/noorvir/tf_models/AlexNet/bvlc_alexnet.npy

# Data Parameters
metric_sample_size: 5                   # number of files to use to approximate data metrics (mean, stddev)
data_metics_filename: dexnet_mini_227
img_min_val: 0
img_max_val: 255


debug: 0                                # run in debug mode or not

# Training parameters
queue_capacity: 30                     # TODO
num_epochs: 20
batch_size: 150
optimiser: adam                         # adam, momentum or rmsprop
loss: wxentropy                         # l2, xentropy, wxentropy, or sparse
pos_train_frac: 0.22                     # fraction of positive training samples (only valid for binary classification)
#data_euqalisation_frac: 0.4

val_frequency: 100                     # steps
log_frequency: 50
save_frequency: 500

data_used_fraction: 0.10                  # fraction of the total training data to use
train_frac: 0.8                         # fraction of data to use for training vs validation


# GUAN-t architecture
architecture:
  img_width: 227
  img_height: 227
  img_channels: 3
  num_classes: 2                        # 2 for binary 6 for quality
  retrain_layers:                       # layers of AlexNet to retrain
    - conv1
    - conv2
    - conv3
    - conv4
    - conv5
    - fc6
    - fc7
  skip_layers:                       # layers of AlexNet to discard
    - fc8
  momentum_rate: 0.7
  learning_rate: 0.0005                  # TODO
  exponential_decay: 0                  # use learning-rate decay - 0 or 1
