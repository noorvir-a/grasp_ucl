# Network Name
network_name: gqunt

# Directories
dataset_dir: /home/noorvir/datasets/gqcnn/dexnet_large_shuffled/
cache_dir: /home/noorvir/datasets/gqcnn/cache/
summary_dir: /home/noorvir/tf_models/GQUN-t/summaries/
checkpoint_dir: /home/noorvir/tf_models/GQUN-t/checkpoints/
model_dir: /home/noorvir/tf_models/GQUN-t/pretrained/        # path to trained GUAN-t model

dataset_name: dexnet_large_shuffled

dataset_config: /home/noorvir/catkin_ws/src/grasp_ucl/cfg/datasets.yaml
pt_model_filename: mahler_2017_GQ/model.ckpt
checkpoint_filename: mahler_2017_GQ/model.ckpt

# Data Parameters
metric_sample_size: 50                   # number of files to use to approximate data metrics (mean, stddev)
data_metics_filename: dexnet_mini_227
img_min_val: 0
img_max_val: 255
datapoints_per_file: 1000
frac_datapoints_from_file: 1.0          # number of data-points to add to data_buffer from current file

# Queue and Thread Parameters
# train
train_data_queue_capacity: 200
train_batch_queue_capacity: 1
num_train_data_dequeue: 100
num_train_data_enqueue_threads: 4
num_train_batch_enqueue_threads: 2
# validation
val_data_queue_capacity: 100
val_batch_queue_capacity: 2
num_val_data_dequeue: 200
num_val_data_enqueue_threads: 1
num_val_batch_enqueue_threads: 1

debug: 0                                # run in debug mode or not

# Training parameters
num_epochs: 10
batch_size: 150
optimiser: momentum                         # adam, momentum or rmsprop
loss: xentropy                          # l2, xentropy, wxentropy, or sparse
learning_rate: 0.001                  # TODO
momentum_rate: 0.5
exponential_decay: 1                  # use learning-rate decay - 0 or 1
lr_decay_rate: 0.96

# Local response Normalisation Parameters
normalisation_radius: 2
normalisation_alpha: 2.0e-05
normalisation_beta: 0.75
normalisation_bias: 1.0

pos_train_frac: 0.5                     # fraction of positive training samples (only valid for binary classification)
weights_init_type: gaussian

val_frequency: 100                     # steps
log_frequency: 10
save_frequency: 6000

data_used_fraction: 1.0                  # fraction of the total training data to use
train_fraction: 0.7                         # fraction of data to use for training vs validation
val_fraction: 0.15                         # fraction of data to use for training vs validation
test_fraction: 0.15                         # fraction of data to use for training vs validation

# GUAN-t architecture
architecture:
  img_width: 32
  img_height: 32
  img_channels: 1
  num_classes: 6                        # 2 for binary 6 for quality
  pose_dim: 1
  train_layers:
    - conv1_1
    - conv1_2
    - conv2_1
    - conv2_2
    - conv3_1
    - conv3_2
    - pc1
    - fc3
    - fc4
    - fc5
  load_layers:
    - conv1_1
    - conv1_2
    - conv2_1
    - conv2_2
    - pc1
    - fc3
    - fc4
  layers:
    conv1_1:
      filt_dim: 7
      num_filt: 64
      pool_size: 1
      pool_stride: 1
      norm: 0
      norm_type: local_response
    conv1_2:
      filt_dim: 5
      num_filt: 64
      pool_size: 2
      pool_stride: 2
      norm: 1
      norm_type: local_response
    conv2_1:
      filt_dim: 3
      num_filt: 64
      pool_size: 1
      pool_stride: 1
      norm: 0
      norm_type: local_response
    conv2_2:
      filt_dim: 3
      num_filt: 64
      pool_size: 1
      pool_stride: 1
      norm: 1
      norm_type: local_response
    conv3_1:
      filt_dim: 3
      num_filt: 64
      pool_size: 1
      pool_stride: 1
      norm: 0
      norm_type: local_response
      use: 1
    conv3_2:
      filt_dim: 3
      num_filt: 64
      pool_size: 1
      pool_stride: 1
      norm: 1
      norm_type: local_response
      use: 1
    pc1:
      out_size: 16
    pc2:
      out_size: 0
    fc3:
      out_size: 1024
      keep_prob: 0.9
    fc4:
      out_size: 1024
      keep_prob: 0.9
    fc5:
      out_size: 6
